{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7abc5c9c-f9ee-4cbe-8e17-64fba01626c3",
   "metadata": {},
   "source": [
    "# Dataset Generation\n",
    "\n",
    "In our analysis, we want to generate a variation of the MNIST dataset that demonstrates the settings in our paper.\n",
    "First we will consider a setting with only one type of digit (i.e. a 0). We will then demonstrate how to generate\n",
    "data according to a latent causal graph over the considered variables.\n",
    "More specifically, consider the following continuous variables:\n",
    "\n",
    "- color\n",
    "- thickness/thinness (width)\n",
    "- fractures\n",
    "- swelling\n",
    "\n",
    "Each of these will be continuously generated within a compact domain according to the causal graph:\n",
    "\n",
    "swelling <- width <- color -> fractures\n",
    "\n",
    "(also shown below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "831ce63e-e1bc-4156-9ad6-9d1137975556",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 11.0.0 (20240428.1522)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"186pt\" height=\"116pt\"\n",
       " viewBox=\"0.00 0.00 186.30 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-112 182.3,-112 182.3,4 -4,4\"/>\n",
       "<!-- A -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>A</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"42.14\" cy=\"-90\" rx=\"42.14\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"42.14\" y=\"-84.95\" font-family=\"Times,serif\" font-size=\"14.00\">swelling</text>\n",
       "</g>\n",
       "<!-- B -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>B</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"42.14\" cy=\"-18\" rx=\"31.9\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"42.14\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">width</text>\n",
       "</g>\n",
       "<!-- A&#45;&gt;B -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>A&#45;&gt;B</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M42.14,-71.7C42.14,-64.41 42.14,-55.73 42.14,-47.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"45.64,-47.62 42.14,-37.62 38.64,-47.62 45.64,-47.62\"/>\n",
       "</g>\n",
       "<!-- C -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>C</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"133.14\" cy=\"-90\" rx=\"29.86\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"133.14\" y=\"-84.95\" font-family=\"Times,serif\" font-size=\"14.00\">color</text>\n",
       "</g>\n",
       "<!-- C&#45;&gt;B -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>C&#45;&gt;B</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M115.16,-75.17C102.03,-65.07 84.01,-51.21 69.16,-39.79\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"71.65,-37.29 61.59,-33.96 67.38,-42.83 71.65,-37.29\"/>\n",
       "</g>\n",
       "<!-- D -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>D</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"135.14\" cy=\"-18\" rx=\"43.16\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"135.14\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">fractures</text>\n",
       "</g>\n",
       "<!-- C&#45;&gt;D -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>C&#45;&gt;D</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M133.63,-71.7C133.84,-64.41 134.09,-55.73 134.32,-47.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"137.82,-47.71 134.61,-37.62 130.82,-47.51 137.82,-47.71\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x107e727a0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "# Create a new directed graph\n",
    "dot = Digraph()\n",
    "\n",
    "# Add nodes\n",
    "dot.node('A', 'swelling')\n",
    "dot.node('B', 'width')\n",
    "dot.node('C', 'color')\n",
    "dot.node('D', 'fractures')\n",
    "\n",
    "# Add edges\n",
    "dot.edge('A', 'B')\n",
    "dot.edge('C', 'B')\n",
    "dot.edge('C', 'D')\n",
    "\n",
    "# Render the graph\n",
    "dot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac2eb58-cae7-4ee7-a386-602c665c17aa",
   "metadata": {},
   "source": [
    "where the degree of swelling is inversely correlated with the width of the digit, which has a relationship with the color. The more red an image is the more wide they are, and the more fractures they have.\n",
    "\n",
    "Now, let us actually generate the data in steps. We will leverage the MORPHO-MNIST API to generate different widths, fractures and swelling.\n",
    "To modify the MNIST dataset to provide color, we will implement a variation of the IRM paper procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19027ec0-bca6-4776-b368-bec88bd82628",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66b4a329-bd63-4b59-b4b4-02b6d534660c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datasets\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ToTensor\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdataset_utils\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/cdrl/lib/python3.10/site-packages/torchvision/__init__.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodulefinder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Module\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/cdrl/lib/python3.10/site-packages/torchvision/models/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malexnet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvnext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdensenet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mefficientnet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/cdrl/lib/python3.10/site-packages/torchvision/models/convnext.py:8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn, Tensor\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functional \u001b[38;5;28;01mas\u001b[39;00m F\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv2dNormActivation, Permute\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstochastic_depth\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StochasticDepth\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_presets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageClassification\n",
      "File \u001b[0;32m~/miniforge3/envs/cdrl/lib/python3.10/site-packages/torchvision/ops/__init__.py:23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgiou_loss\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generalized_box_iou_loss\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv2dNormActivation, Conv3dNormActivation, FrozenBatchNorm2d, MLP, Permute, SqueezeExcitation\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpoolers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MultiScaleRoIAlign\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mps_roi_align\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ps_roi_align, PSRoIAlign\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mps_roi_pool\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ps_roi_pool, PSRoIPool\n",
      "File \u001b[0;32m~/miniforge3/envs/cdrl/lib/python3.10/site-packages/torchvision/ops/poolers.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mboxes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m box_area\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _log_api_usage_once\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mroi_align\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m roi_align\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# copying result_idx_in_level to a specific index in result[]\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# is not supported by ONNX tracing yet.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# _onnx_merge_levels() is an implementation supported by ONNX\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# that merges the levels to the right indices\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39munused\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_onnx_merge_levels\u001b[39m(levels: Tensor, unmerged_results: List[Tensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n",
      "File \u001b[0;32m~/miniforge3/envs/cdrl/lib/python3.10/site-packages/torchvision/ops/roi_align.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List, Union\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn, Tensor\n",
      "File \u001b[0;32m~/miniforge3/envs/cdrl/lib/python3.10/site-packages/torch/_dynamo/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert_frame, eval_frame, resume_execution\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m callback_handler, on_compile_end, on_compile_start\n",
      "File \u001b[0;32m~/miniforge3/envs/cdrl/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:31\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_logging\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m structured\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils_internal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m signpost_event\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msymbolic_shapes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     32\u001b[0m     ConstraintViolationError,\n\u001b[1;32m     33\u001b[0m     GuardOnDataDependentSymNode,\n\u001b[1;32m     34\u001b[0m )\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_module\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _forward_from_src \u001b[38;5;28;01mas\u001b[39;00m original_forward_from_src\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparallel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DistributedDataParallel\n",
      "File \u001b[0;32m~/miniforge3/envs/cdrl/lib/python3.10/site-packages/torch/fx/experimental/symbolic_shapes.py:63\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_guards\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ShapeGuard, Source, TracingContext\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_python_dispatch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_traceable_wrapper_subclass\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sympy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FloorDiv, Mod, IsNonOverlappingAndDenseIndicator\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sympy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msolve\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m try_solve\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sympy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalue_ranges\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m bound_sympy, SymPyValueRangeAnalysis, ValueRanges, ValueRangeError\n",
      "File \u001b[0;32m~/miniforge3/envs/cdrl/lib/python3.10/site-packages/torch/utils/_sympy/functions.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msympy\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msympy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m S\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msympy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fuzzy_and, fuzzy_not, fuzzy_or\n",
      "File \u001b[0;32m~/miniforge3/envs/cdrl/lib/python3.10/site-packages/sympy/__init__.py:108\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01massumptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (AppliedPredicate, Predicate, AssumptionsContext,\n\u001b[1;32m     72\u001b[0m         assuming, Q, ask, register_handler, remove_handler, refine)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpolys\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (Poly, PurePoly, poly_from_expr, parallel_poly_from_expr,\n\u001b[1;32m     75\u001b[0m         degree, total_degree, degree_list, LC, LM, LT, pdiv, prem, pquo,\n\u001b[1;32m     76\u001b[0m         pexquo, div, rem, quo, exquo, half_gcdex, gcdex, invert,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m         legendre_poly, laguerre_poly, apart, apart_list, assemble_partfrac_list,\n\u001b[1;32m    106\u001b[0m         Options, ring, xring, vring, sring, field, xfield, vfield, sfield)\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mseries\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (Order, O, limit, Limit, gruntz, series, approximants,\n\u001b[1;32m    109\u001b[0m         residue, EmptySequence, SeqPer, SeqFormula, sequence, SeqAdd, SeqMul,\n\u001b[1;32m    110\u001b[0m         fourier_series, fps, difference_delta, limit_seq)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (factorial, factorial2, rf, ff, binomial,\n\u001b[1;32m    113\u001b[0m         RisingFactorial, FallingFactorial, subfactorial, carmichael,\n\u001b[1;32m    114\u001b[0m         fibonacci, lucas, motzkin, tribonacci, harmonic, bernoulli, bell, euler,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    133\u001b[0m         Znm, elliptic_k, elliptic_f, elliptic_e, elliptic_pi, beta, mathieus,\n\u001b[1;32m    134\u001b[0m         mathieuc, mathieusprime, mathieucprime, riemann_xi, betainc, betainc_regularized)\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mntheory\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (nextprime, prevprime, prime, primepi, primerange,\n\u001b[1;32m    137\u001b[0m         randprime, Sieve, sieve, primorial, cycle_length, composite,\n\u001b[1;32m    138\u001b[0m         compositepi, isprime, divisors, proper_divisors, factorint,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    149\u001b[0m         continued_fraction_iterator, continued_fraction_reduce,\n\u001b[1;32m    150\u001b[0m         continued_fraction_convergents, continued_fraction, egyptian_fraction)\n",
      "File \u001b[0;32m~/miniforge3/envs/cdrl/lib/python3.10/site-packages/sympy/series/__init__.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgruntz\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gruntz\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mseries\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m series\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapproximants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m approximants\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresidues\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m residue\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequences\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SeqPer, SeqFormula, sequence, SeqAdd, SeqMul\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:879\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:975\u001b[0m, in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1074\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.datasets.utils as dataset_utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a022180-72c6-4eba-91a4-3c441120b5e4",
   "metadata": {},
   "source": [
    "## Generate Images with different colors on the digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f14ed4-18d0-4204-ab5d-0f181450a2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_grayscale_arr(arr, color_value):\n",
    "    \"\"\"Converts grayscale image to a uniform color based on a continuous value\"\"\"\n",
    "    assert arr.ndim == 2\n",
    "    dtype = arr.dtype\n",
    "    h, w = arr.shape\n",
    "    colored_arr = np.zeros((h, w, 3), dtype=dtype)\n",
    "    color = plt.cm.viridis(color_value)[:3]  # Use a continuous colormap like viridis and extract RGB values\n",
    "    mask = arr > 0  # Mask to identify the digit\n",
    "    for i in range(3):\n",
    "        colored_arr[:, :, i][mask] = color[i] * 255  # Apply uniform color to the digit\n",
    "    return colored_arr.astype(dtype)\n",
    "\n",
    "def prepare_colored_mnist(root='./data', overwrite=False):\n",
    "    colored_mnist_dir = os.path.join(root, 'ColoredMNIST')\n",
    "    if not overwrite and os.path.exists(os.path.join(colored_mnist_dir, 'train1.pt')) \\\n",
    "            and os.path.exists(os.path.join(colored_mnist_dir, 'train2.pt')) \\\n",
    "            and os.path.exists(os.path.join(colored_mnist_dir, 'test.pt')):\n",
    "        print('Colored MNIST dataset already exists')\n",
    "        return\n",
    "\n",
    "    print('Preparing Colored MNIST')\n",
    "    train_mnist = datasets.MNIST(root, train=True, download=True)\n",
    "\n",
    "    train1_set = []\n",
    "    train2_set = []\n",
    "    test_set = []\n",
    "\n",
    "    for idx, (im, label) in enumerate(train_mnist):\n",
    "        if idx % 10000 == 0:\n",
    "            print(f'Converting image {idx}/{len(train_mnist)}')\n",
    "        im_array = np.array(im)\n",
    "\n",
    "        # Normalize label to [0, 1] for continuous coloring\n",
    "        color_value = label / 9.0\n",
    "        \n",
    "#         print(idx, label,color_value)\n",
    "        colored_arr = color_grayscale_arr(im_array, color_value)\n",
    "        \n",
    "        assert False\n",
    "        if idx < 20000:\n",
    "            train1_set.append((Image.fromarray(colored_arr), label))\n",
    "        elif idx < 40000:\n",
    "            train2_set.append((Image.fromarray(colored_arr), label))\n",
    "        else:\n",
    "            test_set.append((Image.fromarray(colored_arr), label))\n",
    "\n",
    "    os.makedirs(colored_mnist_dir, exist_ok=True)\n",
    "    torch.save(train1_set, os.path.join(colored_mnist_dir, 'train1.pt'))\n",
    "    torch.save(train2_set, os.path.join(colored_mnist_dir, 'train2.pt'))\n",
    "    torch.save(test_set, os.path.join(colored_mnist_dir, 'test.pt'))\n",
    "\n",
    "def load_colored_mnist(env='train1', root='./data'):\n",
    "    colored_mnist_dir = os.path.join(root, 'ColoredMNIST')\n",
    "    print(f'Loading data from colored mnist: {colored_mnist_dir}')\n",
    "    if env in ['train1', 'train2', 'test']:\n",
    "        data_label_tuples = torch.load(os.path.join(colored_mnist_dir, env) + '.pt')\n",
    "    elif env == 'all_train':\n",
    "        data_label_tuples = torch.load(os.path.join(colored_mnist_dir, 'train1.pt')) + \\\n",
    "                            torch.load(os.path.join(colored_mnist_dir, 'train2.pt'))\n",
    "    else:\n",
    "        raise RuntimeError(f'{env} env unknown. Valid envs are train1, train2, test, and all_train')\n",
    "    return data_label_tuples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26a5a1e-914a-4e74-863f-c1c8dfd8cadd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root = '/Users/adam2392/pytorch_data/'\n",
    "overwrite = True\n",
    "\n",
    "# Prepare Colored MNIST dataset\n",
    "prepare_colored_mnist(root, overwrite=overwrite)\n",
    "\n",
    "# Load some example images\n",
    "data_label_tuples = load_colored_mnist(env='train1', root=root)\n",
    "\n",
    "# Display some example images\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "for i, (img, label) in enumerate(data_label_tuples[:5]):\n",
    "    print(np.array(img).shape)\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].set_title(f'Label: {label}')\n",
    "    axes[i].axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdde9e1-724b-4a3d-a9fe-2ea853828acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[0,1]])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 1.5))\n",
    "img = plt.imshow(a, cmap=\"viridis\")\n",
    "plt.gca().set_visible(False)\n",
    "cax = plt.axes([0.1, 0.2, 0.8, 0.6])\n",
    "plt.colorbar(orientation=\"horizontal\", cax=cax, label='Possible colors')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b6a054-839d-47ed-9c0c-b777094cbf33",
   "metadata": {},
   "source": [
    "## Generate images with different widths using MorphoMNIST API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94449988-0afb-4a47-aa4d-0807309748a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gendis.datasets.morphomnist import perturb, morpho\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cd2b47-6d67-4415-a00a-32837b26d78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_perturbation(image, perturbation):\n",
    "    # Convert image to binary\n",
    "    image = image.squeeze().numpy()\n",
    "    binary_image = np.array(image) > 0\n",
    "#     binary_image = np.array(image.convert('L')) > 0  # Ensure the image is in grayscale and binary\n",
    "\n",
    "    morph = morpho.ImageMorphology(binary_image)\n",
    "    perturbed_image = perturbation(morph)\n",
    "    return Image.fromarray((perturbed_image * 255).astype(np.uint8))\n",
    "\n",
    "# Define the dataset loader with perturbations\n",
    "class PerturbedMNIST(datasets.MNIST):\n",
    "    def __init__(self, root, train=True, transform=None, target_transform=None, download=False, perturbation=None):\n",
    "        super(PerturbedMNIST, self).__init__(root, train=train, transform=transform, target_transform=target_transform, download=download)\n",
    "        self.perturbation = perturbation\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = super(PerturbedMNIST, self).__getitem__(index)\n",
    "        if self.perturbation is not None:\n",
    "            img = apply_perturbation(img, self.perturbation)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        prepare_colored_mnist(root='', overwrite=False)\n",
    "    \n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        return img, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4bed97-c65d-4f4e-a2cd-7d6ccba28eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the perturbations\n",
    "thinning = perturb.Thinning(amount=0.7)\n",
    "thickening = perturb.Thickening(amount=1.0)\n",
    "swelling = perturb.Swelling(strength=3, radius=10)\n",
    "fracture = perturb.Fracture(thickness=1.5, prune=2, num_frac=1)\n",
    "\n",
    "# Apply transformations and load dataset\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "root = '/Users/adam2392/pytorch_data/'\n",
    "train_dataset_thinning = PerturbedMNIST(root=root, train=True, download=True, transform=transform, perturbation=thinning)\n",
    "train_dataset_thickening = PerturbedMNIST(root=root, train=True, download=True, transform=transform, perturbation=thickening)\n",
    "train_dataset_swelling = PerturbedMNIST(root=root, train=True, download=True, transform=transform, perturbation=swelling)\n",
    "train_dataset_fracture = PerturbedMNIST(root=root, train=True, download=True, transform=transform, perturbation=fracture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4dbf2a-b88c-4a22-8937-f807dabe66e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualize some examples\n",
    "def visualize_examples(dataset, title):\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "    for i in range(5):\n",
    "        img, label = dataset[i]\n",
    "        axes[i].imshow(img.squeeze(), cmap='gray')\n",
    "        axes[i].set_title(f'Label: {label}')\n",
    "        axes[i].axis('off')\n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "# Display examples\n",
    "# visualize_examples(train_dataset_thinning, 'Thinning Perturbation')\n",
    "# visualize_examples(train_dataset_thickening, 'Thickening Perturbation')\n",
    "# visualize_examples(train_dataset_swelling, 'Swelling Perturbation')\n",
    "visualize_examples(train_dataset_fracture, 'Fracture Perturbation')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f2ea65-ed9c-4fac-a7f2-01451dd03f6e",
   "metadata": {},
   "source": [
    "## Combining Color and Morpho MNIST\n",
    "\n",
    "First, we'll look at how we can combine perturbations in a VisionDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e75c882-fb04-4359-b556-436bab98b95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_perturbation(image, perturbation):\n",
    "    # Convert image to binary\n",
    "    image = np.array(image)\n",
    "    binary_image = np.array(image) > 0\n",
    "\n",
    "    morph = morpho.ImageMorphology(binary_image)\n",
    "    perturbed_image = perturbation(morph)\n",
    "    return Image.fromarray((perturbed_image * 255).astype(np.uint8))\n",
    "\n",
    "\n",
    "# Define the dataset loader with perturbations\n",
    "class PerturbedMNIST(datasets.MNIST):\n",
    "    def __init__(\n",
    "        self,\n",
    "        root,\n",
    "        train=True,\n",
    "        transform=None,\n",
    "        target_transform=None,\n",
    "        download=False,\n",
    "        perturbations=None,\n",
    "        \n",
    "    ):\n",
    "        super(PerturbedMNIST, self).__init__(\n",
    "            root,\n",
    "            train=train,\n",
    "            transform=transform,\n",
    "            target_transform=target_transform,\n",
    "            download=download,\n",
    "        )\n",
    "\n",
    "        if perturbations is not None and not isinstance(perturbations, list):\n",
    "            raise RuntimeError(\"Should be a list of perturbations\")\n",
    "        self.perturbations = perturbations\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = super(PerturbedMNIST, self).__getitem__(index)\n",
    "        img = img.squeeze()\n",
    "        if self.perturbations is not None:\n",
    "            for perturbation in self.perturbations:\n",
    "                img = torch.Tensor(np.array(img))\n",
    "                img = apply_perturbation(img, perturbation)\n",
    "        \n",
    "        # Normalize label to [0, 1] for continuous coloring\n",
    "        color_value = target / 9.0\n",
    "        img = color_grayscale_arr(np.array(img), color_value)\n",
    "        \n",
    "#         if self.transform is not None:\n",
    "#             img = self.transform(img)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        return img, target\n",
    "\n",
    "    \n",
    "def color_grayscale_arr(arr, color_value):\n",
    "    \"\"\"Converts grayscale image to a uniform color based on a continuous value\"\"\"\n",
    "    assert arr.ndim == 2\n",
    "    dtype = arr.dtype\n",
    "    h, w = arr.shape\n",
    "    colored_arr = np.zeros((h, w, 3), dtype=dtype)\n",
    "    color = plt.cm.viridis(color_value)[:3]  # Use a continuous colormap like viridis and extract RGB values\n",
    "    mask = arr > 0  # Mask to identify the digit\n",
    "    for i in range(3):\n",
    "        colored_arr[:, :, i][mask] = color[i] * 255  # Apply uniform color to the digit\n",
    "    return colored_arr.astype(dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ca9411-db94-4b54-b2a6-9ddb147c1fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualize some examples\n",
    "def visualize_examples(dataset, title):\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "    for i in range(5):\n",
    "        img, label = dataset[i]\n",
    "#         print('here...',\n",
    "#               np.array(img).shape)\n",
    "#         img = np.moveaxis(np.array(img), 0, 2)\n",
    "#         print(img.shape)\n",
    "        img = Image.fromarray(img)\n",
    "        axes[i].imshow(img, cmap='viridis')\n",
    "        axes[i].set_title(f'Label: {label}')\n",
    "        axes[i].axis('off')\n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "perturbations = [\n",
    "    perturb.Thickening(amount=0.2),\n",
    "#     perturb.Swelling(strength=1.75, radius=7),\n",
    "    perturb.Fracture(thickness=1.1, \n",
    "#                      prune=10, \n",
    "                     num_frac=2)\n",
    "]\n",
    "    \n",
    "# Apply transformations and load dataset\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "root = '/Users/adam2392/pytorch_data/'\n",
    "train_dataset = PerturbedMNIST(root=root, train=True, download=False, transform=transform, perturbations=perturbations)\n",
    "    \n",
    "visualize_examples(train_dataset, 'All perturbations and colors')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b3301a-ca18-46b5-9c58-aee6fa08f9e7",
   "metadata": {},
   "source": [
    "## Full CausalMNIST on a single digit\n",
    "\n",
    "Now, we can demonstrate CausalMNIST on a single digit \"0\", where we apply color, fracture and width changes in the form of a latent causal graph among these latent factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c0b9c40-0709-41da-bb68-87eafa706e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gendis.datasets.causalmnist import CausalMNIST\n",
    "from gendis.model import NonlinearNeuralClusteredASCMFlow, LinearNeuralClusteredASCMFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c375fe-88f0-42a4-8d0e-7f313d2e2fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_type = 'chain'\n",
    "root = '/Users/adam2392/pytorch_data/'\n",
    "\n",
    "dataset = CausalMNIST(root=root, graph_type=graph_type, label=0, download=True, train=True, n_jobs=None, intervention_idx=)\n",
    "dataset.prepare_dataset(overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab69d72-9256-4d38-b024-01403307e224",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.prepare_dataset(overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915575a9-cdfb-488d-bd82-c39f6c21db4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for idx in range(5):\n",
    "    img, meta_label = dataset[idx]\n",
    "    print(meta_label)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(img, cmap='viridis')\n",
    "    ax.set_title(f\"Label: {meta_label}\")\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884afcf9-5214-49b1-bb6e-03e6fbb82307",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skewnorm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "numValues = 10000\n",
    "maxValue = 2.0\n",
    "skewness = -6   #Negative values are left skewed, positive values are right skewed.\n",
    "\n",
    "random = skewnorm.rvs(a = skewness / 2,loc=maxValue, \n",
    "                      scale=0.2,\n",
    "                      size=numValues)  #Skewnorm function\n",
    "\n",
    "random = random - min(random)      #Shift the set so the minimum value is equal to zero.\n",
    "random = random / max(random) * 2      #Standadize all the vlues between 0 and 1. \n",
    "# random = random * maxValue         #Multiply the standardized values by the maximum value.\n",
    "\n",
    "#Plot histogram to check skewness\n",
    "plt.hist(random,30,density=True, color = 'red', alpha=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac779126-ed9c-468a-bd22-0491744e2f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skewnorm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_samples = 1000\n",
    "numValues = 10000\n",
    "maxValue = 10\n",
    "skewness = 1   #Negative values are left skewed, positive values are right skewed.\n",
    "\n",
    "width_intervention = stats.skewnorm.rvs(a=0, loc=2, size=(n_samples, 1))\n",
    "width_intervention = width_intervention - min(width_intervention)      #Shift the set so the minimum value is equal to zero.\n",
    "width = (torch.rand(size=(n_samples, 1)) * 2) * width_intervention\n",
    "# width = width - min(width)\n",
    "# width = width / max(width) * 2\n",
    "# random = random * maxValue         #Multiply the standardized values by the maximum value.\n",
    "width = width.squeeze()\n",
    "print(width.shape)\n",
    "#Plot histogram to check skewness\n",
    "plt.hist(width,30,density=True, \n",
    "#          color = 'red', \n",
    "         alpha=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43efed4d-e814-43b3-9ed9-941ee3a40011",
   "metadata": {},
   "source": [
    "# Dataset Loader Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c5b990b-9b1e-4a2e-a368-7df486b6dd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pytorch_lightning as pl\n",
    "from gendis.datasets import ClusteredMultiDistrDataModule, CausalMNIST\n",
    "from gendis.model import NonlinearNeuralClusteredASCMFlow, LinearNeuralClusteredASCMFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2df58bcd-b79f-4dcc-9777-40d2ff0fcad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/Users/adam2392/pytorch_data/\"\n",
    "graph_type = 'chain'\n",
    "\n",
    "batch_size = 32\n",
    "num_workers = 2\n",
    "log_dir='./'\n",
    "intervention_targets_per_distr = []\n",
    "hard_interventions_per_distr = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a96be647-43c7-41bd-b453-3706911df9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from \"/Users/adam2392/pytorch_data/CausalMNIST/chain/chain-0-train.pt\"\n",
      "dict_keys(['width', 'color', 'fracture_thickness', 'fracture_num_fractures', 'label', 'intervention_targets'])\n",
      "torch.Size([3, 28, 28]) {'width': tensor([0.8584]), 'color': tensor([0.4916]), 'fracture_thickness': tensor([9.2616]), 'fracture_num_fractures': tensor([1.]), 'label': 0, 'intervention_targets': [0, 0, 0]}\n",
      "Loading dataset from \"/Users/adam2392/pytorch_data/CausalMNIST/chain/chain-1-train.pt\"\n",
      "dict_keys(['width', 'color', 'fracture_thickness', 'fracture_num_fractures', 'label', 'intervention_targets'])\n",
      "torch.Size([3, 28, 28]) {'width': tensor([4.5250], dtype=torch.float64), 'color': tensor([0.4696]), 'fracture_thickness': tensor([7.4821]), 'fracture_num_fractures': tensor([1.], dtype=torch.float64), 'label': 0, 'intervention_targets': [1, 0, 0]}\n",
      "Loading dataset from \"/Users/adam2392/pytorch_data/CausalMNIST/chain/chain-2-train.pt\"\n",
      "dict_keys(['width', 'color', 'fracture_thickness', 'fracture_num_fractures', 'label', 'intervention_targets'])\n",
      "torch.Size([3, 28, 28]) {'width': tensor([0.1077]), 'color': tensor([0.4356]), 'fracture_thickness': tensor([7.1413]), 'fracture_num_fractures': tensor([0.]), 'label': 0, 'intervention_targets': [0, 0, 1]}\n",
      "Loading dataset from \"/Users/adam2392/pytorch_data/CausalMNIST/chain/chain-3-train.pt\"\n",
      "dict_keys(['width', 'color', 'fracture_thickness', 'fracture_num_fractures', 'label', 'intervention_targets'])\n",
      "torch.Size([3, 28, 28]) {'width': tensor([1.0011]), 'color': tensor([0.3988]), 'fracture_thickness': tensor([9.3166]), 'fracture_num_fractures': tensor([1.]), 'label': 0, 'intervention_targets': [0, 0, 1]}\n"
     ]
    }
   ],
   "source": [
    "datasets = []\n",
    "for intervention_idx in [None, 1, 2, 3]:\n",
    "    dataset = CausalMNIST(\n",
    "        root=root,\n",
    "        graph_type=graph_type,\n",
    "        label=0,\n",
    "        download=True,\n",
    "        train=True,\n",
    "        n_jobs=None,\n",
    "        intervention_idx=intervention_idx,\n",
    "    )\n",
    "    dataset.prepare_dataset(overwrite=False)\n",
    "    datasets.append(dataset)\n",
    "    \n",
    "    intervention_targets_per_distr.append(dataset.intervention_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcf8e20a-d996-4ba1-8356-bb47ee806155",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = ClusteredMultiDistrDataModule(\n",
    "    datasets=datasets,\n",
    "    num_workers=num_workers,\n",
    "    batch_size=5,\n",
    "    intervention_targets_per_distr=intervention_targets_per_distr,\n",
    "    log_dir=log_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "634de3e1-1ab4-4e7d-b1a8-4dde6aab8825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([23692, 3, 28, 28]) 6 torch.Size([23692]) torch.Size([23692]) torch.Size([23692])\n"
     ]
    }
   ],
   "source": [
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "71917263-0835-4302-b9a1-317275ced590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 28, 28]) torch.float32\n",
      "torch.Size([5])\n",
      "[torch.float32, torch.float64, torch.float32, torch.float32, torch.float64, torch.int64, torch.int64]\n"
     ]
    }
   ],
   "source": [
    "# sample a random batch\n",
    "for x, width, color, fracture_thickness, fracture_num_fractures, label, distr_indicators in data_module.train_dataloader():\n",
    "    print(x.shape, x.dtype)\n",
    "    print(distr_indicators.shape)\n",
    "    break\n",
    "    \n",
    "for stuff in data_module.train_dataloader():\n",
    "    print([x.dtype for x in stuff])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e765a167-c2ca-4347-96f0-76438bf5cfed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 1, 2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(distr_indicators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14650fe0-0a4e-4d9b-9ef9-660815c9f447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "728\n"
     ]
    }
   ],
   "source": [
    "def generate_list(x, n_clusters):\n",
    "    quotient = x // n_clusters\n",
    "    remainder = x % n_clusters\n",
    "    result = [quotient] * (n_clusters - 1)\n",
    "    result.append(quotient + remainder)\n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "x = 10\n",
    "print(np.sum(generate_list(728, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c5abfba7-ddd8-40fa-8e13-6c7f12255483",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "adjacency_matrix = np.array([[0, 1, 0], [0, 0, 1], [0, 0, 0]])\n",
    "latent_dim = len(adjacency_matrix)\n",
    "seed = 1234\n",
    "max_epochs=2\n",
    "accelerator='mps'\n",
    "devices=1\n",
    "\n",
    "n_flows = 3  # number of flows to use in nonlinear ICA model\n",
    "lr_scheduler = None\n",
    "lr_min = 0.0\n",
    "lr = 1e-6\n",
    "\n",
    "# Define the model\n",
    "net_hidden_dim = 128\n",
    "net_hidden_dim_cbn = 128\n",
    "net_hidden_layers = 3\n",
    "net_hidden_layers_cbn = 3\n",
    "fix_mechanisms = False\n",
    "\n",
    "model = NonlinearNeuralClusteredASCMFlow(\n",
    "    cluster_sizes=generate_list(728, 3),\n",
    "    graph=adjacency_matrix,\n",
    "    intervention_targets_per_distr=intervention_targets_per_distr,\n",
    "    hard_interventions_per_distr=hard_interventions_per_distr,\n",
    "    n_flows=n_flows,\n",
    "    n_hidden_dim=net_hidden_dim,\n",
    "    n_layers=net_hidden_layers,\n",
    "    lr=lr,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    lr_min=lr_min,\n",
    "    fix_mechanisms=fix_mechanisms,\n",
    ")\n",
    "checkpoint_root_dir = f\"{graph_type}-seed={seed}\"\n",
    "checkpoint_dir = Path(checkpoint_root_dir) / \"default\"\n",
    "logger = None\n",
    "wandb = False\n",
    "check_val_every_n_epoch = 1\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    dirpath=checkpoint_dir,\n",
    "    save_top_k=3,\n",
    "    monitor=\"train_loss\",\n",
    "    every_n_epochs=check_val_every_n_epoch,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=max_epochs,\n",
    "    logger=logger,\n",
    "    devices=devices,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    check_val_every_n_epoch=check_val_every_n_epoch,\n",
    "    accelerator=accelerator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2180953c-762a-4402-b99a-d5fd0bf67bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name    | Type                                | Params\n",
      "----------------------------------------------------------------\n",
      "0 | encoder | NonparametricClusteredCausalEncoder | 7.4 M \n",
      "----------------------------------------------------------------\n",
      "7.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.4 M     Total params\n",
      "29.530    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([23692, 3, 28, 28]) 6 torch.Size([23692]) torch.Size([23692]) torch.Size([23692])\n",
      "Sanity Checking: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam2392/miniforge3/envs/cdrl/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:488: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n",
      "  rank_zero_warn(\n",
      "/Users/adam2392/miniforge3/envs/cdrl/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/cdrl/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:608\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    606\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_unwrap_optimized(model)\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m_lightning_module \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m--> 608\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/cdrl/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:38\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 38\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     41\u001b[0m     trainer\u001b[38;5;241m.\u001b[39m_call_teardown_hook()\n",
      "File \u001b[0;32m~/miniforge3/envs/cdrl/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:650\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    643\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m ckpt_path \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_from_checkpoint\n\u001b[1;32m    644\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_set_ckpt_path(\n\u001b[1;32m    645\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    646\u001b[0m     ckpt_path,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    647\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    648\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    649\u001b[0m )\n\u001b[0;32m--> 650\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/cdrl/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1112\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39mrestore_training_state()\n\u001b[1;32m   1110\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39mresume_end()\n\u001b[0;32m-> 1112\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1114\u001b[0m log\u001b[38;5;241m.\u001b[39mdetail(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_teardown()\n",
      "File \u001b[0;32m~/miniforge3/envs/cdrl/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1191\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting:\n\u001b[1;32m   1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_predict()\n\u001b[0;32m-> 1191\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/cdrl/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1204\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pre_training_routine()\n\u001b[1;32m   1203\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1204\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[38;5;66;03m# enable train mode\u001b[39;00m\n\u001b[1;32m   1207\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/cdrl/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1276\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1274\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m-> 1276\u001b[0m     \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1278\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1280\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/cdrl/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/cdrl/lib/python3.10/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py:152\u001b[0m, in \u001b[0;36mEvaluationLoop.advance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_dataloaders \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    151\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataloader_idx\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m dataloader_idx\n\u001b[0;32m--> 152\u001b[0m dl_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdl_max_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# store batch level output per dataloader\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs\u001b[38;5;241m.\u001b[39mappend(dl_outputs)\n",
      "File \u001b[0;32m~/miniforge3/envs/cdrl/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/cdrl/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py:121\u001b[0m, in \u001b[0;36mEvaluationEpochLoop.advance\u001b[0;34m(self, data_fetcher, dl_max_batches, kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_fetcher, DataLoaderIterDataFetcher):\n\u001b[1;32m    120\u001b[0m     batch_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mcurrent\u001b[38;5;241m.\u001b[39mready\n\u001b[0;32m--> 121\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    123\u001b[0m     batch_idx, batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(data_fetcher)\n",
      "File \u001b[0;32m~/miniforge3/envs/cdrl/lib/python3.10/site-packages/pytorch_lightning/utilities/fetching.py:184\u001b[0m, in \u001b[0;36mAbstractDataFetcher.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetching_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/cdrl/lib/python3.10/site-packages/pytorch_lightning/utilities/fetching.py:275\u001b[0m, in \u001b[0;36mDataFetcher.fetching_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait()\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmove_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/cdrl/lib/python3.10/site-packages/pytorch_lightning/utilities/fetching.py:294\u001b[0m, in \u001b[0;36mDataFetcher.move_to_device\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmove_to_device\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstore_on_device:\n\u001b[0;32m--> 294\u001b[0m         batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m batch\n",
      "File \u001b[0;32m~/miniforge3/envs/cdrl/lib/python3.10/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py:142\u001b[0m, in \u001b[0;36mEvaluationLoop.advance.<locals>.batch_to_device\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbatch_to_device\u001b[39m(batch: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    141\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39m_on_before_batch_transfer(batch, dataloader_idx\u001b[38;5;241m=\u001b[39mdataloader_idx)\n\u001b[0;32m--> 142\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch_to_device\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m batch\n",
      "File \u001b[0;32m~/miniforge3/envs/cdrl/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1494\u001b[0m, in \u001b[0;36mTrainer._call_strategy_hook\u001b[0;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1491\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1494\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/miniforge3/envs/cdrl/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:273\u001b[0m, in \u001b[0;36mStrategy.batch_to_device\u001b[0;34m(self, batch, device, dataloader_idx)\u001b[0m\n\u001b[1;32m    271\u001b[0m device \u001b[38;5;241m=\u001b[39m device \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_device\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 273\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_batch_transfer_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m move_data_to_device(batch, device)\n",
      "File \u001b[0;32m~/miniforge3/envs/cdrl/lib/python3.10/site-packages/pytorch_lightning/core/module.py:342\u001b[0m, in \u001b[0;36mLightningModule._apply_batch_transfer_handler\u001b[0;34m(self, batch, device, dataloader_idx)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply_batch_transfer_handler\u001b[39m(\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28mself\u001b[39m, batch: Any, device: Optional[torch\u001b[38;5;241m.\u001b[39mdevice] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, dataloader_idx: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    340\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    341\u001b[0m     device \u001b[38;5;241m=\u001b[39m device \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m--> 342\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtransfer_batch_to_device\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_hook(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_after_batch_transfer\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch, dataloader_idx)\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m batch\n",
      "File \u001b[0;32m~/miniforge3/envs/cdrl/lib/python3.10/site-packages/pytorch_lightning/core/module.py:330\u001b[0m, in \u001b[0;36mLightningModule._call_batch_hook\u001b[0;34m(self, hook_name, *args)\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    328\u001b[0m         trainer_method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer\u001b[38;5;241m.\u001b[39m_call_lightning_datamodule_hook\n\u001b[0;32m--> 330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    332\u001b[0m     hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, hook_name)\n",
      "File \u001b[0;32m~/miniforge3/envs/cdrl/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1356\u001b[0m, in \u001b[0;36mTrainer._call_lightning_module_hook\u001b[0;34m(self, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1353\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m hook_name\n\u001b[1;32m   1355\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1356\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m   1359\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/miniforge3/envs/cdrl/lib/python3.10/site-packages/pytorch_lightning/core/hooks.py:632\u001b[0m, in \u001b[0;36mDataHooks.transfer_batch_to_device\u001b[0;34m(self, batch, device, dataloader_idx)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransfer_batch_to_device\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch: Any, device: torch\u001b[38;5;241m.\u001b[39mdevice, dataloader_idx: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    576\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Override this hook if your :class:`~torch.utils.data.DataLoader` returns tensors wrapped in a custom\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;124;03m    data structure.\u001b[39;00m\n\u001b[1;32m    578\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;124;03m        - :meth:`apply_to_collection`\u001b[39;00m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 632\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmove_data_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/cdrl/lib/python3.10/site-packages/lightning_fabric/utilities/apply_func.py:101\u001b[0m, in \u001b[0;36mmove_data_to_device\u001b[0;34m(batch, device)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;66;03m# user wrongly implemented the `_TransferableDataType` and forgot to return `self`.\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply_to_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_TransferableDataType\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_to\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/cdrl/lib/python3.10/site-packages/lightning_utilities/core/apply_func.py:66\u001b[0m, in \u001b[0;36mapply_to_collection\u001b[0;34m(data, dtype, function, wrong_dtype, include_none, allow_frozen, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m function(data, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mlist\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, dtype) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data):  \u001b[38;5;66;03m# 1d homogeneous list\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [function(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, dtype) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data):  \u001b[38;5;66;03m# 1d homogeneous tuple\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(function(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data)\n",
      "File \u001b[0;32m~/miniforge3/envs/cdrl/lib/python3.10/site-packages/lightning_utilities/core/apply_func.py:66\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m function(data, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mlist\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, dtype) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data):  \u001b[38;5;66;03m# 1d homogeneous list\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, dtype) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data):  \u001b[38;5;66;03m# 1d homogeneous tuple\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(function(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data)\n",
      "File \u001b[0;32m~/miniforge3/envs/cdrl/lib/python3.10/site-packages/lightning_fabric/utilities/apply_func.py:95\u001b[0m, in \u001b[0;36mmove_data_to_device.<locals>.batch_to\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Tensor) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, torch\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;129;01mand\u001b[39;00m device\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _BLOCKING_DEVICE_TYPES:\n\u001b[1;32m     94\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon_blocking\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m data_output \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data_output\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead."
     ]
    }
   ],
   "source": [
    "trainer.fit(\n",
    "    model,\n",
    "    datamodule=data_module,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb1bbb8-448f-4dc3-b45e-667d521a7d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"Checkpoint dir: {checkpoint_dir}\")\n",
    "trainer.test(datamodule=data_module)\n",
    "\n",
    "# save the output\n",
    "x, v, u, e, int_target, log_prob_gt = data_module.test_dataset[:]\n",
    "print(x.shape)\n",
    "print(e.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cdrl",
   "language": "python",
   "name": "cdrl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
