{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77e34a33-ecbd-4731-a1a5-18405b1736f7",
   "metadata": {},
   "source": [
    "# Try Setting up a New Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e0da01e-0ece-40e4-a38d-76a9fd29e79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1058f2ad-ec19-4190-bceb-124bde99748f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.datasets.utils as dataset_utils\n",
    "\n",
    "from gendis.datasets import CausalMNIST\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import normflows as nf\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from gendis.datasets import CausalMNIST, ClusteredMultiDistrDataModule\n",
    "from gendis.encoder import CausalMultiscaleFlow\n",
    "from gendis.model import NeuralClusteredASCMFlow\n",
    "from gendis.normalizing_flow.distribution import NonparametricClusteredCausalDistribution, ClusteredCausalDistribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bdd0909-d915-4975-ac29-c10bd946c346",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_list(x, n_clusters):\n",
    "    quotient = x // n_clusters\n",
    "    remainder = x % n_clusters\n",
    "    result = [quotient] * (n_clusters - 1)\n",
    "    result.append(quotient + remainder)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af66f152-ac7a-418a-bca5-5f285e5dfea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\n",
      "\n",
      "\tsaving to results/chain-seed=1234-results.npz \n",
      "\n",
      "Global seed set to 1234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with n_jobs: 1\n",
      "Loading dataset from \"/Users/adam2392/pytorch_data/CausalMNIST/chain/chain-0-train.pt\"\n",
      "torch.Size([3, 28, 28]) {'width': tensor([0.5344]), 'color': tensor([0.3977]), 'fracture_thickness': tensor([8.9378]), 'fracture_num_fractures': tensor([1.]), 'label': 0, 'intervention_targets': [0, 0, 0]}\n",
      "Loading dataset from \"/Users/adam2392/pytorch_data/CausalMNIST/chain/chain-1-train.pt\"\n",
      "torch.Size([3, 28, 28]) {'width': tensor([4.0281]), 'color': tensor([0.3975]), 'fracture_thickness': tensor([9.4378]), 'fracture_num_fractures': tensor([1.]), 'label': 0, 'intervention_targets': [1, 0, 0]}\n",
      "Loading dataset from \"/Users/adam2392/pytorch_data/CausalMNIST/chain/chain-2-train.pt\"\n",
      "torch.Size([3, 28, 28]) {'width': tensor([0.4431]), 'color': tensor([0.4416]), 'fracture_thickness': tensor([10.2519]), 'fracture_num_fractures': tensor([0.]), 'label': 0, 'intervention_targets': [0, 0, 1]}\n",
      "Loading dataset from \"/Users/adam2392/pytorch_data/CausalMNIST/chain/chain-3-train.pt\"\n",
      "torch.Size([3, 28, 28]) {'width': tensor([1.2834]), 'color': tensor([0.5551]), 'fracture_thickness': tensor([8.9974]), 'fracture_num_fractures': tensor([0.]), 'label': 0, 'intervention_targets': [0, 0, 1]}\n",
      "torch.Size([23692, 3, 28, 28]) 6 torch.Size([23692]) torch.Size([23692]) torch.Size([23692])\n"
     ]
    }
   ],
   "source": [
    "graph_type = \"chain\"\n",
    "adjacency_matrix = np.array([[0, 1, 0], [0, 0, 1], [0, 0, 0]])\n",
    "latent_dim = len(adjacency_matrix)\n",
    "results_dir = Path(\"./results/\")\n",
    "results_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# root = \"/home/adam2392/projects/data/\"\n",
    "root = '/Users/adam2392/pytorch_data/'\n",
    "# print(args)\n",
    "# root = args.root_dir\n",
    "seed = 1234\n",
    "max_epochs = 10\n",
    "accelerator = 'cpu'\n",
    "batch_size = 10\n",
    "log_dir = './'\n",
    "\n",
    "devices = 1\n",
    "n_jobs = 1\n",
    "num_workers = 2\n",
    "print(\"Running with n_jobs:\", n_jobs)\n",
    "\n",
    "# output filename for the results\n",
    "fname = results_dir / f\"{graph_type}-seed={seed}-results.npz\"\n",
    "\n",
    "# set up logging\n",
    "logger = logging.getLogger()\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logging.info(f\"\\n\\n\\tsaving to {fname} \\n\")\n",
    "\n",
    "# set seed\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "pl.seed_everything(seed, workers=True)\n",
    "\n",
    "# set up transforms for each image to augment the dataset\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        nf.utils.Scale(255.0 / 256.0),  # normalize the pixel values\n",
    "        nf.utils.Jitter(1 / 256.0),    # apply random generation\n",
    "        torchvision.transforms.RandomRotation(350),  # get random rotations\n",
    "    ]\n",
    ")\n",
    "\n",
    "# load dataset\n",
    "datasets = []\n",
    "intervention_targets_per_distr = []\n",
    "hard_interventions_per_distr = None\n",
    "num_distrs = 0\n",
    "for intervention_idx in [None, 1, 2, 3]:\n",
    "    dataset = CausalMNIST(\n",
    "        root=root,\n",
    "        graph_type=graph_type,\n",
    "        label=0,\n",
    "        download=True,\n",
    "        train=True,\n",
    "        n_jobs=None,\n",
    "        intervention_idx=intervention_idx,\n",
    "        transform=transform,\n",
    "    )\n",
    "    dataset.prepare_dataset(overwrite=False)\n",
    "    datasets.append(dataset)\n",
    "    num_distrs += 1\n",
    "    intervention_targets_per_distr.append(dataset.intervention_targets)\n",
    "\n",
    "# now we can wrap this in a pytorch lightning datamodule\n",
    "data_module = ClusteredMultiDistrDataModule(\n",
    "    datasets=datasets,\n",
    "    num_workers=num_workers,\n",
    "    batch_size=batch_size,\n",
    "    intervention_targets_per_distr=intervention_targets_per_distr,\n",
    "    log_dir=log_dir,\n",
    "    flatten=False,\n",
    ")\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27133cfc-63d0-48f2-8f10-4043fd0da99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 8\n",
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "for idx, img in enumerate(data_module.train_dataset):\n",
    "    \n",
    "    print(idx, len(img))\n",
    "    print(img[0].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "776592b2-ec17-4b73-9f6e-50260569bf00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94b76690-4c70-4fba-8b7e-268951647782",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_flows = 3  # number of flows to use in nonlinear ICA model\n",
    "lr_scheduler = None\n",
    "lr_min = 0.0\n",
    "lr = 1e-6\n",
    "\n",
    "# Define the model\n",
    "net_hidden_dim = 128\n",
    "net_hidden_dim_cbn = 128\n",
    "net_hidden_layers = 3\n",
    "net_hidden_layers_cbn = 3\n",
    "fix_mechanisms = False\n",
    "\n",
    "graph = adjacency_matrix\n",
    "cluster_sizes = generate_list(784 * 3, 3)\n",
    "\n",
    "# 01: Define the causal base distribution with the graph\n",
    "causalq0 = NonparametricClusteredCausalDistribution(\n",
    "    adjacency_matrix=graph,\n",
    "    cluster_sizes=cluster_sizes,\n",
    "    intervention_targets_per_distr=intervention_targets_per_distr,\n",
    "    hard_interventions_per_distr=hard_interventions_per_distr,\n",
    "    fix_mechanisms=fix_mechanisms,\n",
    "    n_flows=n_flows,\n",
    "    n_hidden_dim=net_hidden_dim,\n",
    "    n_layers=net_hidden_layers,\n",
    ")\n",
    "\n",
    "causalq0 = ClusteredCausalDistribution(\n",
    "    adjacency_matrix=graph,\n",
    "    cluster_sizes=cluster_sizes,\n",
    "    intervention_targets_per_distr=torch.Tensor(intervention_targets_per_distr),\n",
    "    hard_interventions_per_distr=hard_interventions_per_distr,\n",
    "    fix_mechanisms=fix_mechanisms,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ef9dafe-41ff-43ec-a39a-f8d54846bfd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 1176 (24, 7, 7)\n",
      "12 1176 (6, 14, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam2392/miniforge3/envs/cdrl/lib/python3.10/site-packages/torch/_tensor.py:795: UserWarning: torch.lu is deprecated in favor of torch.linalg.lu_factor / torch.linalg.lu_factor_ex and will be removed in a future PyTorch release.\n",
      "LU, pivots = torch.lu(A, compute_pivots)\n",
      "should be replaced with\n",
      "LU, pivots = torch.linalg.lu_factor(A, compute_pivots)\n",
      "and\n",
      "LU, pivots, info = torch.lu(A, compute_pivots, get_infos=True)\n",
      "should be replaced with\n",
      "LU, pivots, info = torch.linalg.lu_factor_ex(A, compute_pivots) (Triggered internally at /Users/runner/miniforge3/conda-bld/libtorch_1719361051023/work/aten/src/ATen/native/BatchLinearAlgebra.cpp:1994.)\n",
      "  LU, pivots, infos = torch._lu_with_info(\n"
     ]
    }
   ],
   "source": [
    "input_shape = (3, 28, 28)\n",
    "channels = 3\n",
    "\n",
    "# Define flows\n",
    "L = 2\n",
    "K = 3\n",
    "n_dims = np.prod(input_shape)\n",
    "hidden_channels = 256\n",
    "split_mode = 'channel'\n",
    "scale = True\n",
    "\n",
    "stride_factor = 2\n",
    "\n",
    "# Set up flows, distributions and merge operations\n",
    "merges = []\n",
    "flows = []\n",
    "for i in range(L):\n",
    "    flows_ = []\n",
    "    for j in range(K):\n",
    "        n_chs = channels * 2 ** (L + 1 - i)\n",
    "        flows_ += [nf.flows.GlowBlock(n_chs, hidden_channels,\n",
    "                                     split_mode=split_mode, scale=scale)]\n",
    "    flows_ += [nf.flows.Squeeze()]\n",
    "    flows += [flows_]\n",
    "    if i > 0:\n",
    "        merges += [nf.flows.Merge()]\n",
    "        latent_shape = (input_shape[0] * stride_factor ** (L - i), input_shape[1] // stride_factor ** (L - i), \n",
    "                        input_shape[2] // stride_factor ** (L - i))\n",
    "    else:\n",
    "        latent_shape = (input_shape[0] * stride_factor ** (L + 1), input_shape[1] // stride_factor ** L, \n",
    "                        input_shape[2] //stride_factor ** L)\n",
    "    print(n_chs, np.prod(latent_shape), latent_shape)\n",
    "\n",
    "\n",
    "# 03: Define the final normalizing flow model\n",
    "# Construct flow model with the multiscale architecture\n",
    "encoder = CausalMultiscaleFlow(causalq0, flows, merges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd504dc6-7d52-40a8-8150-930b9b166656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 797,024\n"
     ]
    }
   ],
   "source": [
    "def print_num_params(model):\n",
    "    num_params = sum([np.prod(p.shape) for p in model.parameters()])\n",
    "    print(\"Number of parameters: {:,}\".format(num_params))\n",
    "\n",
    "print_num_params(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c02b1d68-2aa8-4d72-b080-32c2b861405e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.Size([1, 3, 28, 28]) torch.Size([1])\n",
      "torch.Size([1, 2352])\n"
     ]
    }
   ],
   "source": [
    "# run a test to make sure this actually works\n",
    "rand_img = torch.arange(28*28*3, dtype=torch.float32).view(1, 3, 28, 28)\n",
    "out = encoder.forward(rand_img)\n",
    "print(rand_img.dtype)\n",
    "print(rand_img.shape, out.shape)\n",
    "print(encoder.inverse_and_log_det(rand_img)[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7876ea23-e72f-4948-8dd5-521072c7dbd2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name    | Type                 | Params\n",
      "-------------------------------------------------\n",
      "0 | encoder | CausalMultiscaleFlow | 797 K \n",
      "-------------------------------------------------\n",
      "789 K     Trainable params\n",
      "7.8 K     Non-trainable params\n",
      "797 K     Total params\n",
      "3.188     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([23692, 3, 28, 28]) 6 torch.Size([23692]) torch.Size([23692]) torch.Size([23692])\n",
      "Sanity Checking DataLoader 0:   0%|                                                                   | 0/2 [00:00<?, ?it/s]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([4, 3])\n",
      "torch.Size([1, 3])\n",
      "Hard intervention...  torch.Size([10, 3])\n",
      "Sanity Checking DataLoader 0:  50%|█████████████████████████████▌                             | 1/2 [00:00<00:00, 16.93it/s]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([4, 3])\n",
      "torch.Size([3, 3])\n",
      "Hard intervention...  torch.Size([10, 3])\n",
      "                                                                                                                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam2392/miniforge3/envs/cdrl/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|                                                                                     | 0/2145 [00:00<?, ?it/s]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([4, 3])\n",
      "torch.Size([2, 3])\n",
      "Epoch 0:   0%|                                                              | 1/2145 [00:01<52:41,  1.47s/it, loss=3.41e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([4, 3])\n",
      "torch.Size([2, 3])\n",
      "Epoch 0:   0%|                                                              | 2/2145 [00:01<29:45,  1.20it/s, loss=3.33e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([2, 3])\n",
      "Epoch 0:   0%|                                                              | 3/2145 [00:01<22:14,  1.61it/s, loss=3.34e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([4, 3])\n",
      "Epoch 0:   0%|                                                              | 4/2145 [00:02<17:57,  1.99it/s, loss=3.33e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([2, 3])\n",
      "Epoch 0:   0%|▏                                                             | 5/2145 [00:02<15:24,  2.31it/s, loss=3.32e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([4, 3])\n",
      "Epoch 0:   0%|▏                                                             | 6/2145 [00:02<14:04,  2.53it/s, loss=3.31e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([5, 3])\n",
      "Epoch 0:   0%|▏                                                             | 7/2145 [00:02<12:52,  2.77it/s, loss=3.32e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([5, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([1, 3])\n",
      "Epoch 0:   0%|▏                                                              | 8/2145 [00:02<12:25,  2.87it/s, loss=3.3e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([6, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([1, 3])\n",
      "Epoch 0:   0%|▎                                                              | 9/2145 [00:03<11:58,  2.97it/s, loss=3.3e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([4, 3])\n",
      "Epoch 0:   0%|▎                                                            | 10/2145 [00:03<11:27,  3.10it/s, loss=3.29e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([4, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([1, 3])\n",
      "Epoch 0:   1%|▎                                                            | 11/2145 [00:03<11:04,  3.21it/s, loss=3.29e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([3, 3])\n",
      "Epoch 0:   1%|▎                                                            | 12/2145 [00:03<10:36,  3.35it/s, loss=3.29e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([6, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([2, 3])\n",
      "Epoch 0:   1%|▎                                                            | 13/2145 [00:03<10:19,  3.44it/s, loss=3.28e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([3, 3])\n",
      "Epoch 0:   1%|▍                                                            | 14/2145 [00:03<10:05,  3.52it/s, loss=3.27e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([4, 3])\n",
      "torch.Size([4, 3])\n",
      "torch.Size([2, 3])\n",
      "Epoch 0:   1%|▍                                                            | 15/2145 [00:04<09:47,  3.62it/s, loss=3.27e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([4, 3])\n",
      "Epoch 0:   1%|▍                                                            | 16/2145 [00:04<09:28,  3.74it/s, loss=3.26e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([4, 3])\n",
      "Epoch 0:   1%|▍                                                            | 17/2145 [00:04<09:20,  3.80it/s, loss=3.26e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([4, 3])\n",
      "torch.Size([3, 3])\n",
      "Epoch 0:   1%|▌                                                            | 18/2145 [00:04<09:04,  3.90it/s, loss=3.26e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([5, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([1, 3])\n",
      "Epoch 0:   1%|▌                                                            | 19/2145 [00:04<08:56,  3.96it/s, loss=3.26e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([1, 3])\n",
      "Epoch 0:   1%|▌                                                            | 20/2145 [00:04<08:49,  4.01it/s, loss=3.25e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([4, 3])\n",
      "torch.Size([4, 3])\n",
      "Epoch 0:   1%|▌                                                            | 21/2145 [00:05<08:45,  4.04it/s, loss=3.24e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([4, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([1, 3])\n",
      "Epoch 0:   1%|▋                                                            | 22/2145 [00:05<08:46,  4.04it/s, loss=3.24e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([4, 3])\n",
      "Epoch 0:   1%|▋                                                            | 23/2145 [00:05<08:39,  4.09it/s, loss=3.23e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([3, 3])\n",
      "Epoch 0:   1%|▋                                                            | 24/2145 [00:05<08:50,  4.00it/s, loss=3.22e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([4, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([4, 3])\n",
      "Epoch 0:   1%|▋                                                            | 25/2145 [00:06<08:44,  4.04it/s, loss=3.21e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([5, 3])\n",
      "torch.Size([3, 3])\n",
      "Epoch 0:   1%|▊                                                             | 26/2145 [00:06<08:42,  4.06it/s, loss=3.2e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([4, 3])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([3, 3])\n",
      "Epoch 0:   1%|▊                                                            | 27/2145 [00:06<08:38,  4.09it/s, loss=3.19e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([5, 3])\n",
      "torch.Size([4, 3])\n",
      "Epoch 0:   1%|▊                                                            | 28/2145 [00:06<08:32,  4.13it/s, loss=3.19e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([2, 3])\n",
      "Epoch 0:   1%|▊                                                            | 29/2145 [00:06<08:26,  4.18it/s, loss=3.18e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([5, 3])\n",
      "Epoch 0:   1%|▊                                                            | 30/2145 [00:07<08:22,  4.21it/s, loss=3.17e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([3, 3])\n",
      "Epoch 0:   1%|▉                                                            | 31/2145 [00:07<08:15,  4.27it/s, loss=3.17e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([5, 3])\n",
      "torch.Size([4, 3])\n",
      "torch.Size([1, 3])\n",
      "Epoch 0:   1%|▉                                                            | 32/2145 [00:07<08:09,  4.31it/s, loss=3.16e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([5, 3])\n",
      "Epoch 0:   2%|▉                                                            | 33/2145 [00:07<08:03,  4.37it/s, loss=3.16e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([6, 3])\n",
      "Epoch 0:   2%|▉                                                            | 34/2145 [00:07<07:58,  4.41it/s, loss=3.15e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([3, 3])\n",
      "Epoch 0:   2%|▉                                                            | 35/2145 [00:07<07:53,  4.46it/s, loss=3.15e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([7, 3])\n",
      "Epoch 0:   2%|█                                                            | 36/2145 [00:07<07:47,  4.51it/s, loss=3.14e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([3, 3])\n",
      "Epoch 0:   2%|█                                                            | 37/2145 [00:08<07:43,  4.55it/s, loss=3.13e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([3, 3])\n",
      "Epoch 0:   2%|█                                                            | 38/2145 [00:08<07:38,  4.59it/s, loss=3.12e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([4, 3])\n",
      "Epoch 0:   2%|█                                                            | 39/2145 [00:08<07:36,  4.61it/s, loss=3.11e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([6, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([1, 3])\n",
      "Epoch 0:   2%|█▏                                                            | 40/2145 [00:08<07:34,  4.63it/s, loss=3.1e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([4, 3])\n",
      "torch.Size([1, 3])\n",
      "Epoch 0:   2%|█▏                                                           | 41/2145 [00:08<07:31,  4.66it/s, loss=3.09e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([3, 3])\n",
      "Epoch 0:   2%|█▏                                                           | 42/2145 [00:08<07:29,  4.68it/s, loss=3.08e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([5, 3])\n",
      "Epoch 0:   2%|█▏                                                           | 43/2145 [00:09<07:26,  4.71it/s, loss=3.07e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([6, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([2, 3])\n",
      "Epoch 0:   2%|█▎                                                           | 44/2145 [00:09<07:22,  4.75it/s, loss=3.06e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([4, 3])\n",
      "torch.Size([4, 3])\n",
      "torch.Size([1, 3])\n",
      "Epoch 0:   2%|█▎                                                           | 45/2145 [00:09<07:21,  4.76it/s, loss=3.06e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([3, 3])\n",
      "Epoch 0:   2%|█▎                                                           | 46/2145 [00:09<07:19,  4.77it/s, loss=3.05e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([6, 3])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([3, 3])\n",
      "Epoch 0:   2%|█▎                                                           | 47/2145 [00:09<07:16,  4.80it/s, loss=3.04e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([5, 3])\n",
      "Epoch 0:   2%|█▎                                                           | 48/2145 [00:09<07:13,  4.83it/s, loss=3.04e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([5, 3])\n",
      "Epoch 0:   2%|█▍                                                           | 49/2145 [00:10<07:11,  4.86it/s, loss=3.03e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([5, 3])\n",
      "torch.Size([3, 3])\n",
      "Epoch 0:   2%|█▍                                                           | 50/2145 [00:10<07:10,  4.87it/s, loss=3.02e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([5, 3])\n",
      "torch.Size([1, 3])\n",
      "Epoch 0:   2%|█▍                                                           | 51/2145 [00:10<07:08,  4.89it/s, loss=3.01e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([5, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([1, 3])\n",
      "Epoch 0:   2%|█▌                                                              | 52/2145 [00:10<07:07,  4.89it/s, loss=3e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([4, 3])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([3, 3])\n",
      "Epoch 0:   2%|█▌                                                           | 53/2145 [00:10<07:06,  4.91it/s, loss=2.98e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([4, 3])\n",
      "torch.Size([2, 3])\n",
      "Epoch 0:   3%|█▌                                                           | 54/2145 [00:10<07:04,  4.93it/s, loss=2.97e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([6, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([1, 3])\n",
      "Epoch 0:   3%|█▌                                                           | 55/2145 [00:11<07:03,  4.94it/s, loss=2.96e+05]Hard intervention...  torch.Size([10, 3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([5, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam2392/miniforge3/envs/cdrl/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                            \r"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can't pickle local object 'EvaluationLoop.advance.<locals>.batch_to_device'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 41\u001b[0m\n\u001b[1;32m     35\u001b[0m trainer\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m     36\u001b[0m     model,\n\u001b[1;32m     37\u001b[0m     datamodule\u001b[38;5;241m=\u001b[39mdata_module,\n\u001b[1;32m     38\u001b[0m )\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# save the final model\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/cdrl/lib/python3.10/site-packages/torch/serialization.py:628\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> 628\u001b[0m         \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_disable_byteorder_record\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/cdrl/lib/python3.10/site-packages/torch/serialization.py:840\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    838\u001b[0m pickler \u001b[38;5;241m=\u001b[39m pickle_module\u001b[38;5;241m.\u001b[39mPickler(data_buf, protocol\u001b[38;5;241m=\u001b[39mpickle_protocol)\n\u001b[1;32m    839\u001b[0m pickler\u001b[38;5;241m.\u001b[39mpersistent_id \u001b[38;5;241m=\u001b[39m persistent_id\n\u001b[0;32m--> 840\u001b[0m \u001b[43mpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    841\u001b[0m data_value \u001b[38;5;241m=\u001b[39m data_buf\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[1;32m    842\u001b[0m zip_file\u001b[38;5;241m.\u001b[39mwrite_record(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, data_value, \u001b[38;5;28mlen\u001b[39m(data_value))\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't pickle local object 'EvaluationLoop.advance.<locals>.batch_to_device'"
     ]
    }
   ],
   "source": [
    "max_epochs = 2\n",
    "# 04a: Define now the full pytorch lightning model\n",
    "model = NeuralClusteredASCMFlow(\n",
    "    encoder=encoder,\n",
    "    lr=lr,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    lr_min=lr_min,\n",
    ")\n",
    "\n",
    "# 04b: Define the trainer for the model\n",
    "checkpoint_root_dir = f\"{graph_type}-seed={seed}\"\n",
    "checkpoint_dir = Path(checkpoint_root_dir)\n",
    "checkpoint_dir.mkdir(exist_ok=True, parents=True)\n",
    "logger = None\n",
    "wandb = False\n",
    "check_val_every_n_epoch = 1\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    dirpath=checkpoint_dir,\n",
    "    save_top_k=5,\n",
    "    monitor=\"train_loss\",\n",
    "    every_n_epochs=check_val_every_n_epoch,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=max_epochs,\n",
    "    logger=logger,\n",
    "    devices=devices,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    check_val_every_n_epoch=check_val_every_n_epoch,\n",
    "    accelerator=accelerator,\n",
    ")\n",
    "\n",
    "# 05: Fit the model and save the data\n",
    "trainer.fit(\n",
    "    model,\n",
    "    datamodule=data_module,\n",
    ")\n",
    "\n",
    "# save the final model\n",
    "torch.save(model, checkpoint_dir / \"model.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b5272838-a8a8-48d2-a861-1fc39222927f",
   "metadata": {},
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <class 'gendis.model.NeuralClusteredASCMFlow'>: it's not the same object as gendis.model.NeuralClusteredASCMFlow",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[111], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# save the final model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/cdrl/lib/python3.10/site-packages/torch/serialization.py:628\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> 628\u001b[0m         \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_disable_byteorder_record\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/cdrl/lib/python3.10/site-packages/torch/serialization.py:840\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    838\u001b[0m pickler \u001b[38;5;241m=\u001b[39m pickle_module\u001b[38;5;241m.\u001b[39mPickler(data_buf, protocol\u001b[38;5;241m=\u001b[39mpickle_protocol)\n\u001b[1;32m    839\u001b[0m pickler\u001b[38;5;241m.\u001b[39mpersistent_id \u001b[38;5;241m=\u001b[39m persistent_id\n\u001b[0;32m--> 840\u001b[0m \u001b[43mpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    841\u001b[0m data_value \u001b[38;5;241m=\u001b[39m data_buf\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[1;32m    842\u001b[0m zip_file\u001b[38;5;241m.\u001b[39mwrite_record(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, data_value, \u001b[38;5;28mlen\u001b[39m(data_value))\n",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <class 'gendis.model.NeuralClusteredASCMFlow'>: it's not the same object as gendis.model.NeuralClusteredASCMFlow"
     ]
    }
   ],
   "source": [
    "# save the final model\n",
    "torch.save(model, checkpoint_dir / \"model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f417ec2e-32c5-4e96-b849-6910e82b6718",
   "metadata": {},
   "source": [
    "## Let's sample from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d760b03c-1e84-4e0c-b9b1-28077f7856e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(batch_size, n_chs, width, height), (batch_size, n_chs, width, height), ..., repeat for n_layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65610e64-7463-4aba-bc12-5d8dbbc4a224",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e645aa3-d4ab-44dd-871a-6fa1f150c826",
   "metadata": {},
   "source": [
    "## RealNVP with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "78411439-862b-4413-a6b9-481647dc236d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1e08dd-a5de-4feb-9e16-44a7beea11d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (3, 28, 28)\n",
    "channels = 3\n",
    "\n",
    "# Define flows\n",
    "L = 2\n",
    "K = 3\n",
    "n_dims = np.prod(input_shape)\n",
    "hidden_channels = 256\n",
    "split_mode = 'channel'\n",
    "scale = True\n",
    "\n",
    "stride_factor = 2\n",
    "\n",
    "# Set up flows, distributions and merge operations\n",
    "merges = []\n",
    "flows = []\n",
    "for i in range(L):\n",
    "    flows_ = []\n",
    "    for j in range(K):\n",
    "        n_chs = channels * 2 ** (L + 1 - i)\n",
    "        flows_ += [nf.flows.GlowBlock(n_chs, hidden_channels,\n",
    "                                     split_mode=split_mode, scale=scale)]\n",
    "    flows_ += [nf.flows.Squeeze()]\n",
    "    flows += [flows_]\n",
    "    if i > 0:\n",
    "        merges += [nf.flows.Merge()]\n",
    "        latent_shape = (input_shape[0] * stride_factor ** (L - i), input_shape[1] // stride_factor ** (L - i), \n",
    "                        input_shape[2] // stride_factor ** (L - i))\n",
    "    else:\n",
    "        latent_shape = (input_shape[0] * stride_factor ** (L + 1), input_shape[1] // stride_factor ** L, \n",
    "                        input_shape[2] //stride_factor ** L)\n",
    "    print(n_chs, np.prod(latent_shape), latent_shape)\n",
    "\n",
    "\n",
    "# 03: Define the final normalizing flow model\n",
    "# Construct flow model with the multiscale architecture\n",
    "encoder = CausalMultiscaleFlow(causalq0, flows, merges)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cdrl",
   "language": "python",
   "name": "cdrl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
